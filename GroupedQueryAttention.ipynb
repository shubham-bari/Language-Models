{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7Dnir19rbSjDe1iRlU51z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubham-bari/Language-Models/blob/main/GroupedQueryAttention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_size_bytes(t):\n",
        "    return t.nelement() * t.element_size()\n",
        "#function to measure memory usage"
      ],
      "metadata": {
        "id": "e7d65AOPO6w7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DirgoeI0D6CC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from typing import Dict\n",
        "\n",
        "class GQA(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out, q_heads, groups, context_len, dropout):\n",
        "\n",
        "    super().__init__()\n",
        "    assert d_out % q_heads == 0, \"d_out must be divisible by q_heads\"\n",
        "    assert q_heads % groups == 0, \"groups must be divisible by q_heads\"\n",
        "\n",
        "    self.d_in=d_in\n",
        "    self.d_out=d_out\n",
        "    self.q_heads=q_heads\n",
        "    self.groups=groups\n",
        "    self.context_len=context_len\n",
        "    self.dropout=dropout\n",
        "\n",
        "    self.head_dim = self.d_in // self.q_heads  #should be same for q and kv\n",
        "    self.kv_heads = q_heads // groups\n",
        "    self.kv_out_dim = self.kv_heads * self.head_dim\n",
        "\n",
        "    self.Wq = nn.Linear(d_in, d_out, bias = False)\n",
        "    self.Wk = nn.Linear(d_in, self.kv_out_dim, bias=False)\n",
        "    self.Wv = nn.Linear(d_in, self.kv_out_dim, bias=False)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.out_proj = nn.Linear(d_out, d_out, bias=False)\n",
        "\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(context_len, context_len), diagonal=1))\n",
        "\n",
        "  def forward(self, x, past_kv:Dict[str, torch.tensor]=None):\n",
        "\n",
        "    b, context_len, d_in = x.shape\n",
        "\n",
        "    q = self.Wq(x)\n",
        "    k = self.Wk(x)\n",
        "    v = self.Wv(x)\n",
        "\n",
        "    # heads*head_dim should always result in matrix d_out (for queries as well as keys), hence change d_out for Wk and Wv accordingly\n",
        "    q = q.view(b, context_len, self.q_heads, self.head_dim)\n",
        "    k = k.view(b, context_len, self.kv_heads, self.head_dim)\n",
        "    v = v.view(b, context_len, self.kv_heads, self.head_dim)\n",
        "\n",
        "    q = q.transpose(1, 2)\n",
        "    k = k.transpose(1, 2)\n",
        "    v = v.transpose(1, 2)\n",
        "\n",
        "    if past_kv is not None:\n",
        "\n",
        "      past_k = past_kv['k']\n",
        "      past_v = past_kv['v']\n",
        "\n",
        "      if past_k is not None:\n",
        "        k = torch.cat((past_k, k), dim=2)\n",
        "      if past_v is not None:\n",
        "        v = torch.cat((past_v, v), dim=2)\n",
        "\n",
        "    context_len_total = k.shape[2]\n",
        "\n",
        "    k = k.repeat_interleave(self.groups, dim=1)\n",
        "    v = v.repeat_interleave(self.groups, dim=1)\n",
        "\n",
        "    attn_scores = q@k.transpose(2, 3)\n",
        "    attn_scores = attn_scores / (self.head_dim**0.5)\n",
        "\n",
        "    if past_kv is None:\n",
        "      causal_mask = self.mask.bool()[:context_len, :context_len_total]\n",
        "      attn_scores.masked_fill_(causal_mask, -torch.inf)\n",
        "    else:\n",
        "      start_idx = context_len_total - context_len\n",
        "      causal_mask = self.mask.bool()[start_idx:start_idx+context_len, :context_len_total]\n",
        "      attn_scores.masked_fill_(causal_mask, -torch.inf)\n",
        "\n",
        "    attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vecs = (attn_weights@v).transpose(1,2)\n",
        "\n",
        "    context_vecs = context_vecs.contiguous().view(b, self.context_len , self.d_out)  #we roll out back to 3 dims\n",
        "    context_vecs = self.out_proj(context_vecs)\n",
        "\n",
        "    present_kv=None\n",
        "\n",
        "    present_kv = {'k': k.detach(), 'v': v.detach()}\n",
        "    return context_vecs, present_kv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "# ---------- Dummy input (same as your MHA test) ----------\n",
        "inputs = torch.tensor([\n",
        "    [1.0, 2.0, 3.0, 4.0, 5.0, 6.0,\n",
        "     7.0, 8.0, 9.0, 10.0, 11.0, 12.0,\n",
        "     13.0, 14.0, 15.0, 16.0, 17.0, 18.0,\n",
        "     19.0, 20.0, 21.0, 22.0, 23.0, 24.0,\n",
        "     25.0, 26.0, 27.0, 28.0, 29.0, 30.0,\n",
        "     31.0, 32.0, 33.0, 34.0, 35.0, 36.0],\n",
        "\n",
        "    [0.5, 1.5, 2.5, 3.5, 4.5, 5.5,\n",
        "     6.5, 7.5, 8.5, 9.5, 10.5, 11.5,\n",
        "     12.5, 13.5, 14.5, 15.5, 16.5, 17.5,\n",
        "     18.5, 19.5, 20.5, 21.5, 22.5, 23.5,\n",
        "     24.5, 25.5, 26.5, 27.5, 28.5, 29.5,\n",
        "     30.5, 31.5, 32.5, 33.5, 34.5, 35.5],\n",
        "\n",
        "    [9.0, 8.0, 7.0, 6.0, 5.0, 4.0,\n",
        "     3.0, 2.0, 1.0, 0.0, -1.0, -2.0,\n",
        "     -3.0, -4.0, -5.0, -6.0, -7.0, -8.0,\n",
        "     -9.0, -10.0, -11.0, -12.0, -13.0, -14.0,\n",
        "     -15.0, -16.0, -17.0, -18.0, -19.0, -20.0,\n",
        "     -21.0, -22.0, -23.0, -24.0, -25.0, -26.0]\n",
        "], dtype=torch.float32)\n",
        "\n",
        "\n",
        "batch = torch.stack((inputs, inputs), dim=0)   # shape = (2,3,6)\n",
        "print(\"Batch shape:\", batch.shape)\n",
        "\n",
        "# ---------- Model ----------\n",
        "batch_size, num_tokens, d_in = batch.shape\n",
        "d_out = d_in\n",
        "\n",
        "gqa = GQA(\n",
        "    d_in=d_in,\n",
        "    d_out=d_out,\n",
        "    context_len=num_tokens,\n",
        "    q_heads=6,\n",
        "    groups=2,\n",
        "    dropout=0.0\n",
        ")\n",
        "\n",
        "# ---------- Run MHA-KV without caching ----------\n",
        "start = time.time()\n",
        "context_vecs, present_kv = gqa(batch)\n",
        "end = time.time()\n",
        "\n",
        "print(\"\\nContext vectors:\\n\", context_vecs)\n",
        "print(\"\\nShape:\", context_vecs.shape)\n",
        "print(\"\\nPresent KV shapes:\")\n",
        "print(\"K:\", present_kv['k'].shape)\n",
        "print(\"V:\", present_kv['v'].shape)\n",
        "\n",
        "print(\"\\nTime:\", end - start, \"seconds\")\n",
        "\n",
        "k_mem = tensor_size_bytes(present_kv['k'])\n",
        "v_mem = tensor_size_bytes(present_kv['v'])\n",
        "\n",
        "total = k_mem + v_mem\n",
        "\n",
        "print(\"K memory:\", k_mem, \"bytes\")\n",
        "print(\"V memory:\", v_mem, \"bytes\")\n",
        "print(\"Total KV memory:\", total / 1024, \"KB\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdLrTlgcOxWS",
        "outputId": "70580c6b-9aa8-493f-f0fe-710da88c96ec"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch shape: torch.Size([2, 3, 36])\n",
            "\n",
            "Context vectors:\n",
            " tensor([[[ -6.1980,  -9.9308,   0.5260,   0.6715,   5.2618,   9.0740,  10.8081,\n",
            "            7.8047,  -6.5301,   4.4666,  -4.1266,   7.8682,  -4.4953,  -1.3451,\n",
            "           -4.5841,  -1.0412,  -6.2217,   1.9541,   5.6271,   7.7625,   1.4324,\n",
            "            1.9269,  -7.8929,  -3.2784,  -6.2498, -10.0581,  -5.0259,  11.3834,\n",
            "            0.2150,  -1.7109,  13.7492,   1.2524,   0.3525,   3.3179,  -6.1689,\n",
            "            0.0749],\n",
            "         [ -6.2260,  -9.8186,   0.6143,   0.7120,   5.2712,   8.9916,  10.7293,\n",
            "            7.7545,  -6.4265,   4.4256,  -4.1391,   7.8505,  -4.4662,  -1.3120,\n",
            "           -4.6133,  -1.0169,  -6.1926,   2.0974,   5.5877,   7.6623,   1.4087,\n",
            "            1.9290,  -7.8667,  -3.2940,  -6.2568, -10.0813,  -5.0360,  11.3647,\n",
            "            0.2924,  -1.6632,  13.6438,   1.3294,   0.3542,   3.2958,  -6.1349,\n",
            "            0.0417],\n",
            "         [  3.2579,  -5.7384,  -8.9809, -11.2953,  -2.1024,   0.2462,   4.1953,\n",
            "            1.1100, -10.1063,   3.3240,   2.0198,  -3.4707,  -0.8542,  -8.7538,\n",
            "            7.8852,  -3.7271,  -7.0415,  -8.4141,  -3.4249,  -5.1608,   5.0928,\n",
            "            1.7108,  15.7297,  -3.2903,  -0.2270,   3.8205,   1.3657,  -5.1133,\n",
            "          -10.2080,  -2.2491,   4.9026, -12.9854,  -1.8670,  -5.0647,  -2.5578,\n",
            "            3.0065]],\n",
            "\n",
            "        [[ -6.1980,  -9.9308,   0.5260,   0.6715,   5.2618,   9.0740,  10.8081,\n",
            "            7.8047,  -6.5301,   4.4666,  -4.1266,   7.8682,  -4.4953,  -1.3451,\n",
            "           -4.5841,  -1.0412,  -6.2217,   1.9541,   5.6271,   7.7625,   1.4324,\n",
            "            1.9269,  -7.8929,  -3.2784,  -6.2498, -10.0581,  -5.0259,  11.3834,\n",
            "            0.2150,  -1.7109,  13.7492,   1.2524,   0.3525,   3.3179,  -6.1689,\n",
            "            0.0749],\n",
            "         [ -6.2260,  -9.8186,   0.6143,   0.7120,   5.2712,   8.9916,  10.7293,\n",
            "            7.7545,  -6.4265,   4.4256,  -4.1391,   7.8505,  -4.4662,  -1.3120,\n",
            "           -4.6133,  -1.0169,  -6.1926,   2.0974,   5.5877,   7.6623,   1.4087,\n",
            "            1.9290,  -7.8667,  -3.2940,  -6.2568, -10.0813,  -5.0360,  11.3647,\n",
            "            0.2924,  -1.6632,  13.6438,   1.3294,   0.3542,   3.2958,  -6.1349,\n",
            "            0.0417],\n",
            "         [  3.2579,  -5.7384,  -8.9809, -11.2953,  -2.1024,   0.2462,   4.1953,\n",
            "            1.1100, -10.1063,   3.3240,   2.0198,  -3.4707,  -0.8542,  -8.7538,\n",
            "            7.8852,  -3.7271,  -7.0415,  -8.4141,  -3.4249,  -5.1608,   5.0928,\n",
            "            1.7108,  15.7297,  -3.2903,  -0.2270,   3.8205,   1.3657,  -5.1133,\n",
            "          -10.2080,  -2.2491,   4.9026, -12.9854,  -1.8670,  -5.0647,  -2.5578,\n",
            "            3.0065]]], grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "Shape: torch.Size([2, 3, 36])\n",
            "\n",
            "Present KV shapes:\n",
            "K: torch.Size([2, 6, 3, 6])\n",
            "V: torch.Size([2, 6, 3, 6])\n",
            "\n",
            "Time: 0.0014586448669433594 seconds\n",
            "K memory: 864 bytes\n",
            "V memory: 864 bytes\n",
            "Total KV memory: 1.6875 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that, GQA has memory usage 2x of MQA but speed is increased by almost ~82%, this highly benefits the speed-accuracy tradeoff by calculating much faster than MQA but still storing ~3x lesser memory than MHA\n"
      ],
      "metadata": {
        "id": "Muu9UtWIR1k6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3yCNuOj3Pt-1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}