{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEXVQwawG+x5AekmJz2Xsb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubham-bari/Language-Models/blob/main/MHA_KV_Cache.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w_uYy7x9Ln0i"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import Dict"
      ],
      "metadata": {
        "id": "wQk0ZTO6SYIo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadKV(nn.Module):\n",
        "\n",
        "  def __init__(self, d_in, d_out, context_len, n_heads, dropout: float=0.0):\n",
        "    super().__init__()\n",
        "    assert d_out%n_heads==0, \"d_out must be divisible by n_heads\"\n",
        "\n",
        "    self.d_in = d_in\n",
        "    self.d_out = d_out\n",
        "    self.n_heads = n_heads\n",
        "    self.head_dim = d_out//n_heads\n",
        "    self.context_len = context_len\n",
        "    self.Wq = nn.Linear(d_in, d_out, bias=False)\n",
        "    self.Wk = nn.Linear(d_in, d_out, bias=False)\n",
        "    self.Wv = nn.Linear(d_in, d_out, bias=False)\n",
        "\n",
        "    self.output_projection = nn.Linear(d_out, d_out, bias = False)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    self.register_buffer(\n",
        "        'mask',\n",
        "        torch.triu(torch.ones(context_len, context_len), diagonal=1)\n",
        "    )\n",
        "\n",
        "  def forward(self, x, past_kv: Dict[str, torch.tensor]=None):\n",
        "\n",
        "    b, context_size, d_out = x.shape\n",
        "    batch_size = b\n",
        "\n",
        "    q = self.Wq(x)\n",
        "    k = self.Wk(x)\n",
        "    v = self.Wv(x)\n",
        "\n",
        "    q = q.view(batch_size, context_size, self.n_heads, self.head_dim)\n",
        "    k = k.view(batch_size, context_size, self.n_heads, self.head_dim)\n",
        "    v = v.view(batch_size, context_size, self.n_heads, self.head_dim)\n",
        "\n",
        "    q = q.transpose(1, 2)\n",
        "    k = k.transpose(1, 2)\n",
        "    v = v.transpose(1, 2)\n",
        "\n",
        "    # If past_kv provided, concatenate along seq_len dim (dim=2)\n",
        "    if past_kv is not None:\n",
        "\n",
        "      # expected shapes for past_kv['k'] and ['v']: (b, num_heads, seq_len_past, head_dim)\n",
        "      past_k = past_kv['k']\n",
        "      past_v = past_kv['v']\n",
        "\n",
        "      if past_k is not None:\n",
        "        k = torch.cat((past_k, k), dim=2)  # new_seq_len = seq_len_past+ seq_len\n",
        "\n",
        "      if past_v is not None:\n",
        "        v = torch.cat((past_v, v), dim=2)\n",
        "\n",
        "    seq_len_total = k.shape[2]\n",
        "\n",
        "    attn_scores = torch.matmul(q, k.transpose(2,3))  #k=(b, n_heads, head_dim, s)\n",
        "    attn_scores = attn_scores/math.sqrt(self.head_dim)  #scaling\n",
        "\n",
        "    if past_kv is None:\n",
        "      causal_mask = self.mask.bool()[:context_size, :seq_len_total]\n",
        "      attn_scores.masked_fill_(causal_mask, -torch.inf)\n",
        "    else:\n",
        "      start_idx = seq_len_total - context_size\n",
        "      causal_mask = self.mask.bool()[start_idx:start_idx+context_size, :seq_len_total]\n",
        "      attn_scores.masked_fill_(causal_mask, -torch.inf)\n",
        "\n",
        "    attn_weights = torch.softmax(attn_scores, dim=-1)\n",
        "    attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "    context_vecs = (attn_weights@v).transpose(1,2)\n",
        "\n",
        "    context_vecs = context_vecs.contiguous().view(b, self.context_len , self.d_out)  #we roll out back to 3 dims\n",
        "    context_vecs = self.output_projection(context_vecs)\n",
        "\n",
        "    present_kv=None\n",
        "\n",
        "    present_kv = {'k': k.detach(), 'v': v.detach()}\n",
        "    return context_vecs, present_kv\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NPCLSuyFSZ4m"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mha = MultiHeadKV(d_in=6, d_out=6, n_heads=2, context_len = 3)\n",
        "cache = None\n",
        "generated = []\n",
        "# imagine we generate token by token; each step we feed only the new token embedding (seq_len=1)\n",
        "for t in range(10):\n",
        "    new_token_embed = torch.randn(2, 3, 6)   # batch=2, three new token\n",
        "    out, cache = mha(new_token_embed)\n",
        "\n",
        "    print(\"\\n\\nOuputs are:\\n\", out)\n",
        "    print(\"\\n\\nCache are:\\n\", cache)\n",
        "    # out shape: (2, 1, 512)\n",
        "    # cache['k'].shape -> (2, num_heads, t+1, head_dim)\n",
        "    # cache['v'].shape -> (2, num_heads, t+1, head_dim)\n",
        "    # pass out into subsequent MLP / logits head etc.\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEG2WzPFYCdc",
        "outputId": "37ba3788-3649-4b45-a918-099c05a4055a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Ouputs are:\n",
            " tensor([[[ 0.0022, -0.0203,  0.2001,  0.3570,  0.0913, -0.1347],\n",
            "         [-0.3427,  0.1300, -0.0896,  0.4539,  0.1334, -0.4004],\n",
            "         [-0.1972,  0.0609, -0.0726,  0.2446,  0.1138, -0.2240]],\n",
            "\n",
            "        [[-0.0747, -0.0401,  0.3982,  0.3793,  0.2116, -0.1631],\n",
            "         [ 0.1301, -0.1844,  0.3920,  0.2036,  0.2023,  0.0905],\n",
            "         [ 0.1228, -0.1421,  0.2808,  0.1890,  0.1380,  0.0028]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "\n",
            "Cache are:\n",
            " {'k': tensor([[[[-1.0803, -0.1004, -0.6312],\n",
            "          [-0.9167, -0.5473,  0.3107],\n",
            "          [ 0.2617,  0.2593, -0.0087]],\n",
            "\n",
            "         [[-0.9150, -0.3980,  0.5276],\n",
            "          [-1.5294, -0.6495, -0.3476],\n",
            "          [ 0.3810,  0.0409, -0.3407]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0320,  0.0768, -0.3775],\n",
            "          [ 0.0827, -0.3101, -0.2378],\n",
            "          [ 0.0571, -0.4368, -0.4180]],\n",
            "\n",
            "         [[ 0.1320,  0.5006, -0.1276],\n",
            "          [ 0.7761,  0.1697, -0.9751],\n",
            "          [-0.6248,  0.4890,  0.2609]]]]), 'v': tensor([[[[-0.2846, -0.4014, -0.3111],\n",
            "          [-0.7647, -0.1179, -0.1360],\n",
            "          [ 0.1392,  0.2697,  0.0724]],\n",
            "\n",
            "         [[ 0.1156, -0.0442, -0.3297],\n",
            "          [ 0.4676, -1.1669,  1.0686],\n",
            "          [ 0.4287,  0.1284, -0.0438]]],\n",
            "\n",
            "\n",
            "        [[[-0.5094, -0.5267,  0.5457],\n",
            "          [-0.2201,  0.0457, -0.3688],\n",
            "          [-0.0331, -0.9913,  0.3560]],\n",
            "\n",
            "         [[-0.1273, -0.4867, -0.8075],\n",
            "          [ 0.5102,  0.5610, -1.0039],\n",
            "          [-0.4825,  0.1884,  0.5015]]]])}\n",
            "\n",
            "\n",
            "Ouputs are:\n",
            " tensor([[[-0.0324, -0.0157,  0.0593,  0.2077, -0.0074, -0.0340],\n",
            "         [ 0.0963, -0.0678,  0.1567, -0.0436,  0.1506,  0.2004],\n",
            "         [ 0.0825, -0.0343,  0.1547,  0.0704,  0.1101,  0.0805]],\n",
            "\n",
            "        [[-0.2469,  0.0528, -0.2690,  0.2216,  0.0728, -0.3499],\n",
            "         [ 0.0731, -0.0976,  0.4144,  0.3368,  0.0723,  0.0298],\n",
            "         [-0.0534, -0.0238, -0.0341,  0.0568,  0.0514, -0.0487]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "\n",
            "Cache are:\n",
            " {'k': tensor([[[[-0.5244, -0.4437,  0.0298],\n",
            "          [-0.5423,  1.1277, -0.1432],\n",
            "          [-0.5382, -0.1243, -0.2172]],\n",
            "\n",
            "         [[-0.4150, -0.3662, -0.0926],\n",
            "          [ 0.7010, -0.6985,  0.1117],\n",
            "          [-0.4996, -0.2384,  0.5042]]],\n",
            "\n",
            "\n",
            "        [[[-0.1902, -0.5477, -0.0936],\n",
            "          [-0.4271, -0.2449, -0.1598],\n",
            "          [ 0.7757,  0.1534,  0.1636]],\n",
            "\n",
            "         [[-0.8965,  0.0457, -0.3999],\n",
            "          [ 0.6668, -0.0529, -0.0053],\n",
            "          [ 0.6465,  0.3614, -0.7750]]]]), 'v': tensor([[[[-0.1856, -0.0125, -0.5115],\n",
            "          [ 0.0187,  1.1687, -0.3230],\n",
            "          [-0.0308, -0.1996, -0.2510]],\n",
            "\n",
            "         [[ 0.0750,  0.0883,  0.0464],\n",
            "          [ 0.9232, -0.2500, -1.3624],\n",
            "          [-0.2157,  0.0799, -0.0582]]],\n",
            "\n",
            "\n",
            "        [[[-0.2978, -0.5589,  0.1281],\n",
            "          [-0.3814,  0.0571, -0.5684],\n",
            "          [ 0.1522,  0.2022,  0.3313]],\n",
            "\n",
            "         [[ 0.2392, -0.2322,  0.9265],\n",
            "          [-0.3554,  0.2388, -1.7560],\n",
            "          [ 0.4548,  0.1191,  0.2308]]]])}\n",
            "\n",
            "\n",
            "Ouputs are:\n",
            " tensor([[[-0.1440,  0.1788, -0.2534, -0.1192, -0.2578, -0.1097],\n",
            "         [-0.2769,  0.2321, -0.2750,  0.0669, -0.2294, -0.2911],\n",
            "         [-0.3200,  0.1695, -0.2382,  0.1274, -0.0838, -0.2920]],\n",
            "\n",
            "        [[-0.2512,  0.2502, -0.1294,  0.2602, -0.1933, -0.3417],\n",
            "         [-0.1074,  0.1362, -0.1361,  0.0277, -0.1331, -0.1374],\n",
            "         [ 0.0810, -0.0894, -0.0517, -0.0111,  0.0862, -0.0132]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "\n",
            "Cache are:\n",
            " {'k': tensor([[[[ 0.4915, -0.1274,  0.5165],\n",
            "          [ 0.0540, -0.5289,  0.3528],\n",
            "          [-0.6226,  0.2951, -0.0581]],\n",
            "\n",
            "         [[-0.0426,  0.1415,  0.3387],\n",
            "          [-0.9454,  0.1348,  0.3727],\n",
            "          [-0.9563, -0.4537,  0.0303]]],\n",
            "\n",
            "\n",
            "        [[[-0.6950, -0.1012, -0.0435],\n",
            "          [ 0.4450,  0.1536, -0.0472],\n",
            "          [-0.1131, -0.1038, -0.7019]],\n",
            "\n",
            "         [[-1.1868, -0.3646,  1.1472],\n",
            "          [ 0.5486,  0.1896, -0.4273],\n",
            "          [-0.1264,  0.2126, -0.7597]]]]), 'v': tensor([[[[ 0.2934,  0.0060,  0.1725],\n",
            "          [-0.1304, -0.5746,  0.3101],\n",
            "          [-0.3654,  0.0866,  0.2276]],\n",
            "\n",
            "         [[-0.6623, -0.0532,  0.8136],\n",
            "          [-0.7396, -0.5078,  1.2325],\n",
            "          [ 0.6419, -0.9416,  0.5725]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0130, -0.3547, -0.0564],\n",
            "          [ 0.2466,  0.1778,  0.0533],\n",
            "          [-0.1621, -0.4234,  0.0920]],\n",
            "\n",
            "         [[-0.6497, -0.3447,  0.6711],\n",
            "          [ 0.3570,  0.4097, -0.0460],\n",
            "          [ 0.9000,  0.3663, -0.1141]]]])}\n",
            "\n",
            "\n",
            "Ouputs are:\n",
            " tensor([[[-0.5035,  0.2266, -0.0035,  0.5176,  0.0326, -0.2940],\n",
            "         [-0.2685,  0.1391,  0.0202,  0.2386,  0.0097, -0.1198],\n",
            "         [-0.1509,  0.1749, -0.0834,  0.1165, -0.0407, -0.1663]],\n",
            "\n",
            "        [[ 0.3515, -0.2088,  0.3469,  0.0227,  0.0534,  0.2707],\n",
            "         [ 0.0948, -0.1296,  0.3158,  0.2229,  0.1366,  0.0880],\n",
            "         [ 0.0503, -0.0683,  0.3085,  0.2776,  0.0236,  0.0722]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "\n",
            "Cache are:\n",
            " {'k': tensor([[[[-1.0260, -0.4977,  0.7829],\n",
            "          [-0.2082,  0.3662,  0.1350],\n",
            "          [ 0.6546, -0.4083,  0.0370]],\n",
            "\n",
            "         [[-0.8400, -1.0471, -0.0927],\n",
            "          [-0.0023, -0.2883,  0.3944],\n",
            "          [ 0.4280,  0.4802, -0.1634]]],\n",
            "\n",
            "\n",
            "        [[[-0.4039,  0.0133, -0.5602],\n",
            "          [-0.5899, -0.2453, -0.0071],\n",
            "          [-0.5549, -0.7213,  0.4072]],\n",
            "\n",
            "         [[ 0.2095, -0.0733,  0.1063],\n",
            "          [-0.2192, -0.2977, -0.4145],\n",
            "          [-0.1343, -0.4986,  0.1418]]]]), 'v': tensor([[[[-0.6393,  0.6139, -0.7791],\n",
            "          [ 0.0331,  0.3660, -0.0427],\n",
            "          [ 0.3703, -0.3139, -0.0195]],\n",
            "\n",
            "         [[ 0.0915, -0.9730,  0.2721],\n",
            "          [-0.0395, -0.3021, -0.1694],\n",
            "          [-0.4307,  0.8027,  0.2514]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0416, -0.0997, -0.3924],\n",
            "          [-0.6051,  0.0604, -0.2732],\n",
            "          [-0.1695,  0.1912, -0.9178]],\n",
            "\n",
            "         [[ 0.1570,  0.6266, -0.9067],\n",
            "          [ 0.3351, -0.4748, -0.5406],\n",
            "          [-0.5244,  0.2189, -0.2973]]]])}\n",
            "\n",
            "\n",
            "Ouputs are:\n",
            " tensor([[[ 0.3575, -0.2752,  0.0986, -0.0810, -0.0543,  0.1509],\n",
            "         [-0.0497,  0.0237,  0.0320,  0.1278, -0.1061, -0.0363],\n",
            "         [ 0.0365, -0.0481,  0.0567,  0.0987, -0.0636,  0.0029]],\n",
            "\n",
            "        [[-0.3174,  0.1302, -0.3875, -0.0154,  0.0059, -0.1546],\n",
            "         [-0.0014, -0.1033, -0.0730, -0.0793,  0.1836,  0.0344],\n",
            "         [ 0.0204, -0.0814, -0.0537, -0.0369,  0.1099, -0.0130]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "\n",
            "Cache are:\n",
            " {'k': tensor([[[[ 0.8960, -0.7941, -0.3770],\n",
            "          [-0.5045, -0.2508,  0.6318],\n",
            "          [-0.0614, -0.4411, -0.0503]],\n",
            "\n",
            "         [[ 0.5312,  0.9975, -0.8643],\n",
            "          [-0.4641, -0.6191,  0.3877],\n",
            "          [-0.0737,  0.0544, -0.3055]]],\n",
            "\n",
            "\n",
            "        [[[-0.0589, -0.3015,  0.6956],\n",
            "          [ 0.5671,  0.1794, -0.5010],\n",
            "          [ 0.4549, -0.3058, -0.3050]],\n",
            "\n",
            "         [[-0.3426, -0.4720, -0.5603],\n",
            "          [ 0.8021,  0.6534, -1.0550],\n",
            "          [ 0.1661,  0.6305, -0.2155]]]]), 'v': tensor([[[[ 0.1521, -0.9216,  0.1910],\n",
            "          [-0.1833,  0.4072, -0.4677],\n",
            "          [-0.1160, -0.2239, -0.2123]],\n",
            "\n",
            "         [[-0.1802,  1.1054,  0.0999],\n",
            "          [-0.4030, -0.5233,  0.2745],\n",
            "          [-0.0014,  0.2486,  0.0037]]],\n",
            "\n",
            "\n",
            "        [[[-0.1438,  0.5030, -0.2796],\n",
            "          [-0.1745, -0.2304,  0.4686],\n",
            "          [ 0.0419, -0.6531,  0.3096]],\n",
            "\n",
            "         [[ 0.3908, -0.4424,  0.9152],\n",
            "          [ 0.7551,  0.2304, -0.6997],\n",
            "          [-0.2564,  0.4196,  0.0132]]]])}\n",
            "\n",
            "\n",
            "Ouputs are:\n",
            " tensor([[[ 0.0711,  0.0248, -0.1509, -0.2639, -0.0686,  0.2108],\n",
            "         [-0.0256,  0.0400,  0.0111,  0.0511, -0.0279, -0.0030],\n",
            "         [-0.1664,  0.1060,  0.0251,  0.1767, -0.0145, -0.1413]],\n",
            "\n",
            "        [[-0.5065,  0.3388, -0.3415,  0.1807,  0.0603, -0.4226],\n",
            "         [-0.3501,  0.2679, -0.1018,  0.3571, -0.0725, -0.3905],\n",
            "         [-0.2511,  0.2452, -0.1807,  0.0640, -0.1117, -0.2316]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "\n",
            "Cache are:\n",
            " {'k': tensor([[[[-0.3749,  0.3200,  0.2434],\n",
            "          [-0.5033, -0.1977, -0.2017],\n",
            "          [-0.0511, -0.2030,  0.2457]],\n",
            "\n",
            "         [[ 0.0306, -0.6929,  0.2775],\n",
            "          [-0.6273, -0.0374,  0.5169],\n",
            "          [-0.4806,  0.1655,  0.0991]]],\n",
            "\n",
            "\n",
            "        [[[-1.0360,  0.5441,  0.1604],\n",
            "          [-0.7020, -0.6190, -0.0511],\n",
            "          [ 0.4491,  0.4552,  0.3201]],\n",
            "\n",
            "         [[-1.3060, -0.9069,  0.9062],\n",
            "          [-1.0352, -0.1887,  0.9367],\n",
            "          [ 0.2481,  0.0448,  0.3938]]]]), 'v': tensor([[[[ 0.2942,  0.7847, -0.5572],\n",
            "          [-0.2989, -0.4657,  0.0381],\n",
            "          [-0.5059, -0.3615,  0.4349]],\n",
            "\n",
            "         [[ 0.3073,  0.1372,  0.0276],\n",
            "          [-0.4449, -0.3281, -0.1179],\n",
            "          [-0.4549, -0.9294,  0.2278]]],\n",
            "\n",
            "\n",
            "        [[[-0.2265,  0.3882,  0.0313],\n",
            "          [-0.1820, -0.6418, -0.2818],\n",
            "          [ 0.3840,  0.3346,  0.2867]],\n",
            "\n",
            "         [[ 0.2240, -1.2087,  0.6739],\n",
            "          [-0.9813, -0.0988,  0.2817],\n",
            "          [-0.2402, -0.1209,  0.3937]]]])}\n",
            "\n",
            "\n",
            "Ouputs are:\n",
            " tensor([[[ 0.2406, -0.1836,  0.2504,  0.0202, -0.0734,  0.2780],\n",
            "         [-0.0139, -0.0557,  0.1894,  0.2142, -0.0419,  0.0356],\n",
            "         [-0.0380,  0.0740, -0.0400,  0.0449, -0.0918, -0.0565]],\n",
            "\n",
            "        [[ 0.0128,  0.0585, -0.1536, -0.1682, -0.0243,  0.0328],\n",
            "         [ 0.1323, -0.0496,  0.1764, -0.0281,  0.0751,  0.1360],\n",
            "         [ 0.2412,  0.1230,  0.0078,  0.0777, -0.0634, -0.1789]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "\n",
            "Cache are:\n",
            " {'k': tensor([[[[ 0.2781, -0.6505,  0.2267],\n",
            "          [-0.3090, -0.5643,  0.4471],\n",
            "          [ 0.8868, -0.0294,  0.0514]],\n",
            "\n",
            "         [[ 0.6657,  0.1206, -0.6774],\n",
            "          [-0.5263, -0.1884, -0.0854],\n",
            "          [ 0.5822,  0.4615, -0.3880]]],\n",
            "\n",
            "\n",
            "        [[[-0.3429,  0.4370, -0.1065],\n",
            "          [-0.4288,  0.3720, -0.4326],\n",
            "          [ 1.1223, -1.4569,  0.0926]],\n",
            "\n",
            "         [[-0.2719, -0.3745,  0.5276],\n",
            "          [ 0.3675, -0.1246,  0.1612],\n",
            "          [ 0.2581,  1.0909,  0.3022]]]]), 'v': tensor([[[[ 0.0040,  0.0776, -0.5509],\n",
            "          [-0.4922, -0.1179, -0.1461],\n",
            "          [ 0.5389, -0.0319,  0.1809]],\n",
            "\n",
            "         [[-0.1124,  0.6982, -0.4083],\n",
            "          [-0.3702, -0.6387,  0.2735],\n",
            "          [ 0.0587,  0.7488,  0.5179]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2214,  0.2799, -0.0865],\n",
            "          [-0.1584,  0.1495, -0.1706],\n",
            "          [ 0.7086, -1.2897, -0.1565]],\n",
            "\n",
            "         [[ 0.1692, -0.0442,  0.1221],\n",
            "          [ 0.2070,  0.0601, -1.2553],\n",
            "          [-1.8522,  1.7499,  0.8419]]]])}\n",
            "\n",
            "\n",
            "Ouputs are:\n",
            " tensor([[[ 0.0583, -0.1207,  0.2485,  0.0392,  0.3715, -0.0366],\n",
            "         [ 0.0735, -0.1711,  0.2392,  0.1575,  0.3149, -0.0331],\n",
            "         [ 0.0658, -0.1036,  0.1391,  0.0566,  0.2357,  0.0093]],\n",
            "\n",
            "        [[ 0.0670,  0.0463, -0.0429,  0.0474, -0.3645,  0.0576],\n",
            "         [-0.0953,  0.0770,  0.0597,  0.1622, -0.1216, -0.0673],\n",
            "         [-0.1573,  0.0879, -0.0064,  0.2692, -0.0604, -0.1954]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "\n",
            "Cache are:\n",
            " {'k': tensor([[[[ 0.1789,  0.7793, -0.7523],\n",
            "          [-0.0622, -0.3752, -0.5029],\n",
            "          [-0.3683,  0.4691, -0.1012]],\n",
            "\n",
            "         [[ 0.3852,  0.5764, -0.1863],\n",
            "          [ 0.0355,  0.3500, -0.8795],\n",
            "          [-0.0062, -0.4549,  0.1734]]],\n",
            "\n",
            "\n",
            "        [[[-0.0623, -0.8359,  0.4215],\n",
            "          [-0.4503,  0.3467, -0.0167],\n",
            "          [-0.4611, -0.6868, -0.0480]],\n",
            "\n",
            "         [[-0.2506, -0.2106,  0.2729],\n",
            "          [-0.3355, -0.2014,  0.4441],\n",
            "          [-0.9771, -0.0968, -0.3494]]]]), 'v': tensor([[[[-0.3064, -0.3397,  0.9007],\n",
            "          [-0.4565, -0.5265,  0.0924],\n",
            "          [ 0.1379,  0.4987, -0.2284]],\n",
            "\n",
            "         [[ 0.5137, -0.4587, -0.9610],\n",
            "          [ 0.5346,  0.1213, -0.4690],\n",
            "          [ 0.4972, -0.0015, -0.1922]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2816, -0.0831, -0.7125],\n",
            "          [-0.3589,  0.0558,  0.2196],\n",
            "          [-0.4929, -0.5413, -0.0593]],\n",
            "\n",
            "         [[-0.7520,  0.6737,  0.5944],\n",
            "          [-0.0989, -0.8251, -0.3533],\n",
            "          [ 0.1274, -0.3663,  0.6441]]]])}\n",
            "\n",
            "\n",
            "Ouputs are:\n",
            " tensor([[[ 0.0096,  0.0886, -0.3434, -0.3603, -0.1700,  0.1335],\n",
            "         [-0.0703,  0.1654, -0.6327, -0.6074, -0.1657,  0.1135],\n",
            "         [ 0.0279,  0.1139, -0.5264, -0.6170, -0.1861,  0.1482]],\n",
            "\n",
            "        [[ 0.1753, -0.0673,  0.3597,  0.1976, -0.1351,  0.0146],\n",
            "         [ 0.1405, -0.1647,  0.3555,  0.2880,  0.1848, -0.0432],\n",
            "         [ 0.1431, -0.1952,  0.5294,  0.4288,  0.1798,  0.0300]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "\n",
            "Cache are:\n",
            " {'k': tensor([[[[-0.0102,  0.2149,  0.4147],\n",
            "          [ 0.5586,  1.1317,  0.8199],\n",
            "          [ 1.0191, -0.2113,  0.1280]],\n",
            "\n",
            "         [[-0.0172, -0.4894,  0.2861],\n",
            "          [ 0.1987, -0.6209,  0.3687],\n",
            "          [ 0.6867,  0.6950, -0.0241]]],\n",
            "\n",
            "\n",
            "        [[[ 0.3352, -0.3668, -0.2813],\n",
            "          [ 0.0468, -0.4935, -0.5682],\n",
            "          [-0.9127, -0.4694, -0.5379]],\n",
            "\n",
            "         [[ 0.2476,  0.6534,  0.2723],\n",
            "          [ 0.2286,  0.5881, -1.1461],\n",
            "          [ 0.2031, -0.1671, -0.3283]]]]), 'v': tensor([[[[ 0.4494,  0.6495, -0.3525],\n",
            "          [ 0.9287,  1.3970,  0.1587],\n",
            "          [ 0.5330, -0.2908,  0.2416]],\n",
            "\n",
            "         [[ 0.0841,  0.1717,  0.5849],\n",
            "          [ 0.5726, -0.2485,  1.4521],\n",
            "          [-0.6436,  0.7853,  0.3085]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0225, -0.7458,  0.2059],\n",
            "          [-0.6829, -0.7111,  0.2250],\n",
            "          [-0.7139, -0.2313, -0.6838]],\n",
            "\n",
            "         [[-0.8507,  0.4415, -0.4253],\n",
            "          [ 0.4944,  0.0231, -0.8216],\n",
            "          [ 0.1127,  0.1839, -1.8489]]]])}\n",
            "\n",
            "\n",
            "Ouputs are:\n",
            " tensor([[[-0.3061,  0.1501, -0.5092,  0.0060,  0.0733, -0.4554],\n",
            "         [-0.2255,  0.1504, -0.0802,  0.1964, -0.0422, -0.2624],\n",
            "         [-0.1940,  0.0411, -0.0678,  0.2523,  0.0334, -0.2163]],\n",
            "\n",
            "        [[-0.4608,  0.1122, -0.3950,  0.1979,  0.2945, -0.4679],\n",
            "         [-0.2270,  0.0741, -0.1647,  0.1485,  0.1459, -0.2957],\n",
            "         [-0.1829,  0.0684, -0.1965,  0.0549,  0.1026, -0.2227]]],\n",
            "       grad_fn=<UnsafeViewBackward0>)\n",
            "\n",
            "\n",
            "Cache are:\n",
            " {'k': tensor([[[[ 0.0299,  0.0463, -0.2883],\n",
            "          [-0.4530, -0.1963,  0.3387],\n",
            "          [-0.2043, -1.0797,  0.2417]],\n",
            "\n",
            "         [[-1.0481,  0.2341,  0.0782],\n",
            "          [-0.2777, -0.3418,  0.5871],\n",
            "          [-0.4108, -0.0675, -1.0727]]],\n",
            "\n",
            "\n",
            "        [[[-0.1715, -0.0783,  0.0086],\n",
            "          [-0.1674,  0.1631, -0.4028],\n",
            "          [ 0.3670, -0.0372,  0.1876]],\n",
            "\n",
            "         [[-0.8608, -0.0462, -0.7160],\n",
            "          [-0.3590,  0.1712,  0.4954],\n",
            "          [ 0.1317,  0.1356, -0.3093]]]]), 'v': tensor([[[[-0.0599, -0.6579,  0.7241],\n",
            "          [-0.1987,  0.1137, -0.3198],\n",
            "          [-0.5591, -0.2987, -0.4226]],\n",
            "\n",
            "         [[ 0.2352, -0.4782,  1.2845],\n",
            "          [-0.6596, -0.3717, -0.2196],\n",
            "          [ 0.2680, -0.0430,  0.3849]]],\n",
            "\n",
            "\n",
            "        [[[-0.5451, -0.2265,  0.4916],\n",
            "          [-0.0183, -0.4425,  0.3106],\n",
            "          [ 0.0880,  0.0588,  0.1447]],\n",
            "\n",
            "         [[ 0.8013, -0.9606,  0.9083],\n",
            "          [-0.2129, -0.0943, -0.0476],\n",
            "          [ 0.1087,  0.0078,  0.3970]]]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B5fO-yGVYRUc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}